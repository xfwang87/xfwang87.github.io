
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Xiangfeng Wang's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Xiangfeng Wang">
  <meta name="keywords" content="Xiangfeng Wang, 王祥丰, wangxiangfeng, Xiangfeng, Wang, MARL, Distributed Optimization">
  <meta name="author" content="Xiangfeng Wang" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/MAIL-logo.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>X. Wang</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">X. Wang</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/wangxiangfeng.jpg">
      <h1>Xiangfeng Wang</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
        I am an associate professor at <a href="http://cs.ecnu.edu.cn/">School of computer Science and Technology</a> <a href="https://www.ecnu.edu.cn/">East China normal University</a>. Before that, I received my bachelor's degree and doctorate degree from Nanjing University in 2009 and 2014 respectively under the supervision of Professor Bingsheng He. During my PhD study, I was supported by the National Scholarship Council for joint training at the University of Minnesota under the supervision of Professor <a href="https://sse.cuhk.edu.cn/en/faculty/luozhiquan">Zhi-Quan Luo</a>.
	</p>
        <p class="w3-center">
          <a href="mailto:xfwang@cs.ecnu.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=YpGMkgsAAAAJ&hl=en">Google Scholar</a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="research-areas">
   <h2>Research Areas</h2>
      <p><li> Multi-agent Learning and Distributed Optimization
      <p><li> Learn to Optimize
      <p><li> Trustworthy Machine Learning: fairness, privacy and etc.
  </div>
	      
<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>
    <p class="w3-justify">
        Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
    </p>

        <h4><li>Adder Neural Networks</li></h4>
        <img style="width:96%;" src="images/AdderNet.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/AdderNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        </p> 

  </div>

 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>

    <h4> Journal Papers:</h4>

    <ol>

      <p>
      <li><strong>Structured Cooperative Reinforcement Learning with Time-varying Composite Action Space</strong>
      <br>
      Wenhao Li, <strong>Xiangfeng Wang</strong>, Bo Jin, Dixin Luo, and Hongyuan Zha
      <br>
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 2022 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/9507301/">paper</a> 
      </p>
      
      <p>
      <li><strong>Perturbation Techniques for Convergence Analysis of Proximal Gradient Method and Other First-order Algorithms via Variational Analysis</strong>
      <br>
      <strong>Xiangfeng Wang</strong>, Jane J. Ye, Xiaoming Yuan, Shangzhi Zeng, and Jin Zhang
      <br>
      <em>Set-Valued and Variational Analysis</em> 2022 | <a style="color: #447ec9" href="https://link.springer.com/article/10.1007/s11228-020-00570-0">paper</a> 
      </p>
															
      <p>
      <li><strong>Learning to Schedule Multi-NUMA Virtual Machines via Reinforcement Learning</strong>
      <br>
      Junjie Sheng, Yiqiu Hu, Wenli Zhou, Lei Zhu, Bo Jin, Jun Wang, and <strong>Xiangfeng Wang</strong>
      <br>
      <em>Pattern Recognition</em> 2022 | <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0031320321004349">paper</a> 
      </p>
      
      <p>
      <li><strong>The O(1/n) Worst-case Convergence Rate of ADMM with Variable Penalty Parameters</strong>
      <br>
      Xingju Cai, <strong>Xiangfeng Wang</strong>, and Wenxing Zhang
      <br>
      <em>Numerical Mathematics A Journal of Chinese Universities</em> 2021 | <strong>Commemorate the 100th anniversary of the birth of Professor Xuchu He</strong> 
      </p>
	
      <p>
      <li><strong>Boundary-aware Supervoxel-level Iteratively Refined Interactive 3D Image Segmentation with Multi-agent Reinforcement Learning</strong>
      <br>
      Chaofan Ma, Qisen Xu, <strong>Xiangfeng Wang</strong>, Bo Jin, Xiaoyu Zhang, Yanfeng Wang, and Ya Zhang
      <br>
      <em>IEEE Transactions on Medical Imaging</em> 2021 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/9311659">paper</a> 
      </p>
																		 
      <p>
      <li><strong>Distributed and Parallel ADMM for Structured Nonconvex Optimization Problem</strong>
      <br>
      <strong>Xiangfeng Wang</strong>, Junchi Yan, Bo Jin, and Wwenhao Li
      <br>
      <em>IEEE Transactions on Cybernetics</em> 2021 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/8945408">paper</a> 
      </p>
																	     
      <p>
      <li><strong>Survey on Fairness in Trustworthy Machine Learning</strong>
      <br>
      Wenyan Liu, Chuyun Shen, <strong>Xiangfeng Wang</strong>, Bo Jin, Xingjian Lu, Xiangfeng Wang, Hongyuan Zha, and Jifeng He
      <br>
      <em>Journal of Software</em> 2021 | <a style="color: #447ec9" href="http://www.jos.org.cn/josen/article/abstract/6214">paper</a> 
      </p>
															    
      <p>
      <li><strong>The Distance Between Convex Sets with Minkowski Sum Structure: Application to Collision Detection</strong>
      <br>
      <strong>Xiangfeng Wang</strong>, Junping Zhang, and Wenxing Zhang
      <br>
      <em>Computational Optimization and Applications</em> 2020 | <a style="color: #447ec9" href="https://link.springer.com/article/10.1007/s10589-020-00211-0">paper</a> 
      </p>
																	     </ol>


, . , 77, 2020, pp.465–490.
M. Hong, T.-H. Chang, Xiangfeng Wang, M. Razaviyayn, S. Ma, and Z.-Q. Luo, A Block Successive Upper Bound Minimization Method of Multipliers for Linearly Constrained Convex Optimization. Mathematics of Operations Research, 45(3), 2020, pp.833-861.
C. Li, Xiangfeng Wang, W. Dong, J. Yan, Q. Liu, and H. Zha, Active Sample Learning and Feature Selection: A Unified Approach. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(6), 2019, pp.1382-1396.
C. Li, F. Wei, W. Dong, Q. Liu, Xiangfeng Wang, and X. Zhang, Dynamic Structure Embedded Online Multiple-output Regression for Streaming Data. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(2), 2019, pp.323-336.
H. Yue, Q. Yang, Xiangfeng Wang, and X. Yuan, Implementing the ADMM to Big Datasets: A Case Study of LASSO. SIAM Journal on Scientific Computing, 40(5), 2018, pp.A3121-A3156.
Xiangfeng Wang, W. Zhang, J. Yan, X. Yuan, and H. Zha, On the Flexibility of Block Coordinate Descent for Large-Scale Optimization. Neurocomputing, 272, 2018, pp.471-480.
M. Hong, Xiangfeng Wang, M. Razaviyayn and Z.-Q. Luo, Iteration Complexity Analysis of Block Coordinate Descent Methods. Mathematical Programming Series A, 163, 2017, pp.85-114.
T.-H. Chang, M. Hong, W.-C. Liao, and Xiangfeng Wang, Asynchronous Distributed ADMM for Large-Scale Optimization-Part I: Algorithm and Convergence Analysis. IEEE Transactions on Signal Processing, 64(12), 2016, pp.3118-3130.
T.-H. Chang, W.-C. Liao, M. Hong, and Xiangfeng Wang, Asynchronous Distributed ADMM for Large-Scale Optimization-Part II: Linear Convergence Analysis and Numerical Performances. IEEE Transactions on Signal Processing, 64(12), 2016, pp.3131-3144.
Xiangfeng Wang, On the Convergence Rate of a Class of Proximal-Based Decomposition Methods for Monotone Variational Inequalities. Journal of the Operations Research Society of China, 3(3), 2015, pp.347-362.
Xiangfeng Wang, M. Hong, S. Ma, and Z.-Q. Luo, Solving Multiple-Block Separable Convex Minimization Problems using Two-Block ADMM. Pacific Journal of Optimization, 11(4), 2015, pp.645-667.
T.-H. Chang, M. Hong, and Xiangfeng Wang, Multi-Agent Distributed Large-Scale Optimization by Inexact Consensus ADMM. IEEE Transactions on Signal Processing, 63(2), 2015, pp.482-497. ESI高被引论文 IEEE Signal Processing Society Best Paper Award
X. Luo, Xiangfeng Wang, Z. Suo, and Z. Li, Efficient InSAR Phase Noise Reduction via Total Variation Regularization. Science China (Information Sciences), 2015, 58(8), 1-13.
Xiangfeng Wang, and X. Yuan, The Linearized Alternating Direction Method of Multipliers for Dantzig Selector. SIAM Journal of Scientific Computing, 34(5), 2012, pp.A2792-A2811.
							    
    <h4> Conference Papers:</h4>

    <ol>
     
      <p>
      <li><strong>Transformer in Transformer</strong>
      <br>
      Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/CV-Backbones">code</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/TNT">MindSpore code</a> 
      </p>

      </ol>

    </p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2020, <a href="https://mp.weixin.qq.com/s/dORL01lgFNDHgjp3KMJmiQ">Nomination for Outstanding Youth Paper Award</a>, <a href="https://worldaic.com.cn/portal/en/aboutus.html">WAIC</a></p>               
    <p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
    <p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship</a></p>
    <p><li> 2017, President's PhD Scholarship, Peking University</p>
    <p><li> 2017, National Scholarship for Graduate Students</p>
    <p><li> 2016, National Scholarship for Graduate Students</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a><a href="https://hebingsheng.github.io/">&#10025;</a></br>

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
